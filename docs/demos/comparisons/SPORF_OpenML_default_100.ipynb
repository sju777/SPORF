{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook loads in the OpenML 100 suite and classifies each dataset using the SPORF classifier. The task IDs, accuracies, and runtimes of each dataset are compiled into .txt files for later analysis.\n",
    "#### Kernel dies repeatedly during runs, so either using a different server or running the code with batches of the datasets rather than all at once is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import sklearn\n",
    "from rerf.rerfClassifier import rerfClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "benchmark_suite = openml.study.get_suite('OpenML100')  # obtain the benchmark suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146195\n",
      "Data set: connect-4; Accuracy: 0.8092\n",
      "Time: 0:23:47.774947\n",
      "146606\n",
      "Data set: higgs; Accuracy: 0.7177\n",
      "Time: 0:48:30.138461\n",
      "146607\n",
      "Data set: SpeedDating; Accuracy: 0.8595\n",
      "Time: 0:03:10.681410\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.pipeline.make_pipeline(sklearn.preprocessing.Imputer(), rerfClassifier())\n",
    "\n",
    "for task_id in benchmark_suite.tasks[97:]:  # iterate over all tasks, change indices inside square brackets to specify batch of datasets\n",
    "    try:\n",
    "        f = open(\"SPORF_accuracies_100.txt\",\"a\")\n",
    "        startTime = datetime.now()\n",
    "        task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "        openml.config.apikey = '204cdba18d110fd68ad24b131ea92030'  # set the OpenML Api Key\n",
    "        run = openml.runs.run_model_on_task(clf, task)  # run the classifier on the task\n",
    "        score = run.get_metric_fn(sklearn.metrics.accuracy_score)  # print accuracy score\n",
    "        print(task_id)\n",
    "        print('Data set: %s; Accuracy: %0.4f' % (task.get_dataset().name,score.mean()))\n",
    "        print('Time: '+ str(datetime.now() - startTime))\n",
    "        f.write('%i,%s,%0.4f,%s,\\n' % (task_id,task.get_dataset().name,score.mean(),str(datetime.now() - startTime)))\n",
    "        f.close()\n",
    "    except:\n",
    "        print('Error in' + str(task_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tealeaf] *",
   "language": "python",
   "name": "conda-env-tealeaf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
