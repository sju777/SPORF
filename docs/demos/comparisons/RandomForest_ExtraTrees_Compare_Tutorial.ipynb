{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "benchmark_suite = openml.study.get_suite('OpenML100')  # obtain the benchmark suite\n",
    "benchmark_suite = openml.study.get_suite('OpenML-CC18')  # obtain the benchmark suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following sections uses the OpenML CC-18 and 100 suites and classifies each dataset using the sklearn's RandomForest classifier and ExtraTrees classifier. The task IDs, accuracies, and runtimes of each dataset are compiled into .txt files for later analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a scikit-learn classifier\n",
    "clf = sklearn.pipeline.make_pipeline(sklearn.preprocessing.Imputer(),\n",
    "                                     sklearn.ensemble.RandomForestClassifier())\n",
    "\n",
    "for task_id in benchmark_suite.tasks:  # iterate over all tasks\n",
    "    try:\n",
    "        f = open(\"sklearnRF_accuracies_100.txt\",\"a\")\n",
    "        startTime = datetime.now()\n",
    "        task = openml.tasks.get_task(task_id) # download the OpenML task\n",
    "        openml.config.apikey = 'c9ea8896542dd998ea42685f14e2bc14'  # set the OpenML Api Key\n",
    "        run = openml.runs.run_model_on_task(clf, task) # run classifier on splits (requires API key)\n",
    "        score = run.get_metric_fn(sklearn.metrics.accuracy_score) # print accuracy score\n",
    "        print('Data set: %s; Accuracy: %0.2f' % (task.get_dataset().name,score.mean()))\n",
    "        print('Time: '+ str(datetime.now() - startTime))\n",
    "        f.write('%i,%s,%0.4f,%s,\\n' % (task_id,task.get_dataset().name,score.mean(),str(datetime.now() - startTime)))\n",
    "        f.close()\n",
    "    except:\n",
    "        print('Error in' + str(task_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTrees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tealeaf] *",
   "language": "python",
   "name": "conda-env-tealeaf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
